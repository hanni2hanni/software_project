from flask import Flask, Response, jsonify, stream_with_context
from flask_cors import CORS  # å¯¼å…¥ CORS
import pyaudio
import wave
import numpy as np
import os
import assemblyai as aai
import time
from pygame import mixer
from threading import Thread
import queue
from queue import Queue

app = Flask(__name__)
CORS(app)
message_queue = Queue()
is_listening = False  # çŠ¶æ€æ ‡å¿—ä½

# é…ç½®éŸ³é¢‘å‚æ•°
SAMPLE_RATE = 16000  # é‡‡æ ·ç‡ 16000 Hz
CHANNELS = 1         # å•å£°é“
SAMPLE_WIDTH = 2     # 16-bit PCMï¼ˆ2 å­—èŠ‚ï¼‰
CHUNK = 1024         # æ¯æ¬¡è¯»å–çš„å¸§æ•°
OUTPUT_DIR = "wavs"  # ä¸´æ—¶æ–‡ä»¶ä¿å­˜ç›®å½•
TRIGGER_FILE = os.path.join(OUTPUT_DIR, "trigger.wav")  # è§¦å‘è¯ä¸´æ—¶æ–‡ä»¶
COMMAND_FILE = os.path.join(OUTPUT_DIR, "command.wav")  # æŒ‡ä»¤æ–‡ä»¶
RMS_THRESHOLD = 0.0010  # RMS èƒ½é‡é˜ˆå€¼ï¼Œç”¨äº VAD
SILENCE_DURATION = 4  # é™éŸ³æŒç»­æ—¶é—´ï¼ˆç§’ï¼‰

has_started = False  # æ ‡è®°æ˜¯å¦å·²ç»è§¦å‘â€œå¼€å§‹å½•éŸ³â€


# é…ç½® AssemblyAI API
aai.settings.api_key = "0a91719634f847eebefd17e7b3005c72"

# ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
os.makedirs(OUTPUT_DIR, exist_ok=True)

# æ’­æ”¾çŠ¶æ€ç®¡ç†
is_playing = False
music_file = os.path.join(OUTPUT_DIR, "music1_converted.wav")
navigation_file = os.path.join(OUTPUT_DIR, "navigation_converted.wav")
security_file = os.path.join(OUTPUT_DIR, "security_converted.wav")

# åœ¨å…¨å±€æ§åˆ¶å½•éŸ³çŠ¶æ€
is_listening = False

# åˆå§‹åŒ– pygame mixer
mixer.init(frequency=SAMPLE_RATE, size=-16, channels=CHANNELS)

def compute_rms(audio_data):
    """è®¡ç®—éŸ³é¢‘æ•°æ®çš„ RMSï¼ˆå‡æ–¹æ ¹ï¼‰å€¼"""
    audio_array = np.frombuffer(audio_data, dtype=np.int16)
    if len(audio_array) == 0:
        print("è­¦å‘Šï¼šéŸ³é¢‘æ•°æ®ä¸ºç©º")
        return 0.0
    squared_mean = np.mean(audio_array**2)
    if not np.isfinite(squared_mean):
        print("è­¦å‘Šï¼šRMS è®¡ç®—ç»“æœæ— æ•ˆï¼Œsquared_mean =", squared_mean)
        return 0.0
    if squared_mean <= 0 or np.isnan(squared_mean):
        rms = 0.0
    else:
        rms = np.sqrt(squared_mean) / 32768.0

    #rms = np.sqrt(squared_mean) / 32768.0  # å½’ä¸€åŒ–åˆ° 0-1
    return rms

def transcribe_audio(audio_path):
    """ä½¿ç”¨ AssemblyAI è½¬å½•éŸ³é¢‘"""
    #å‘Šè¯‰ AssemblyAI ä½¿ç”¨ä¸­æ–‡è¯­éŸ³è¯†åˆ«æ¨¡å‹
    config = aai.TranscriptionConfig(language_code="zh")
    #åˆ›å»ºè½¬å½•å™¨
    transcriber = aai.Transcriber(config=config)
    #å‘èµ·è½¬å½•è¯·æ±‚
    transcript = transcriber.transcribe(audio_path)
    if transcript.status == "completed":
        return transcript.text
    print(f"è½¬å½•çŠ¶æ€: {transcript.status}")
    return None

def play_audio(file_path):
    """æ’­æ”¾éŸ³é¢‘æ–‡ä»¶"""
    print(f"å°è¯•æ’­æ”¾æ–‡ä»¶: {file_path}, å­˜åœ¨: {os.path.exists(file_path)}")
    if os.path.exists(file_path):
        try:
            mixer.music.load(file_path)
            print("æ–‡ä»¶åŠ è½½æˆåŠŸ")
            mixer.music.play()
            print(f"æ’­æ”¾: {file_path}")
            # ç­‰å¾…æ’­æ”¾å®Œæˆ
            while mixer.music.get_busy():
                pass
            print("æ’­æ”¾å®Œæˆ")
        except Exception as e:
            print(f"æ’­æ”¾å¤±è´¥: {e}")
    else:
        print(f"é”™è¯¯: æ–‡ä»¶ {file_path} ä¸å­˜åœ¨")

def stop_audio():
    """åœæ­¢æ’­æ”¾éŸ³é¢‘"""
    global is_playing
    if is_playing:
        mixer.music.stop()
        is_playing = False
        print("åœæ­¢æ’­æ”¾")

# æŒ‡ä»¤å¤„ç†å‡½æ•°
def handle_open_music():
    play_audio(music_file)

def handle_notice_road():
    play_audio(security_file)

def handle_open_navigation():
    play_audio(navigation_file)

def handle_close_music():
    stop_audio()

# æŒ‡ä»¤æ˜ å°„å­—å…¸ï¼ˆæ¨¡æ‹Ÿ switch...caseï¼‰
command_handlers = {
    "æ‰“å¼€éŸ³ä¹": handle_open_music,
    "å·²ç»æ³¨æ„é“è·¯": handle_notice_road,
    "æ‰“å¼€å¯¼èˆª": handle_open_navigation,
    "å…³é—­éŸ³ä¹": handle_close_music,
    "é–‹å•“éŸ³æ¨‚": handle_open_music,
    "å·²ç¶“æ³¨æ„é“è·¯": handle_notice_road,
    "æ‰“é–‹å°èˆª": handle_open_navigation,
    "é—œé–‰éŸ³æ¨‚": handle_close_music
}
#å®æ—¶ç›‘å¬éº¦å…‹é£è¾“å…¥ï¼Œå¹¶æ£€æµ‹æ˜¯å¦è¯´å‡ºäº†â€œå¼€å§‹å½•éŸ³â€ï¼Œä½œä¸ºè§¦å‘è¯æ¥å¯åŠ¨å½•éŸ³è¿‡ç¨‹ã€‚
def record_trigger():
    """ç›‘å¬è§¦å‘è¯ 'å¼€å§‹å½•éŸ³'"""
    audio = pyaudio.PyAudio()
    # æ‰“å¼€éŸ³é¢‘æµï¼Œç”¨äºå®æ—¶è¯»å–éº¦å…‹é£æ•°æ®
    stream = audio.open(format=pyaudio.paInt16,
                        channels=CHANNELS,
                        rate=SAMPLE_RATE,
                        input=True,
                        frames_per_buffer=CHUNK)
    message_queue.put("æ­£åœ¨ç›‘å¬è§¦å‘è¯â€œå¼€å§‹å½•éŸ³â€...")
    #print("ç›‘å¬ä¸­ï¼Œè¯·è¯´ 'å¼€å§‹å½•éŸ³' è§¦å‘å½•éŸ³...")
    frames = []
    silence_counter = 0
    recording = False
    max_trigger_duration = 3

    while True:
        data = stream.read(CHUNK, exception_on_overflow=False)
        rms = compute_rms(data)# è®¡ç®—å½“å‰éŸ³é¢‘æ®µçš„èƒ½é‡å¤§å°
        #å¦‚æœå£°éŸ³å¤§äºé˜ˆå€¼ï¼Œåˆ™è®¤ä¸ºå¼€å§‹è®²è¯ â†’ recording = True
        if rms > RMS_THRESHOLD:
            recording = True
            frames.append(data)
            silence_counter = 0
        elif recording:
            silence_counter += CHUNK / SAMPLE_RATE
            frames.append(data)
            if silence_counter > SILENCE_DURATION:
                break

        if recording and len(frames) * CHUNK / SAMPLE_RATE > max_trigger_duration:
            break

    stream.stop_stream()
    stream.close()
    audio.terminate()

    if not frames:
        #print("æœªæ£€æµ‹åˆ°å£°éŸ³")
        message_queue.put("æœªæ£€æµ‹åˆ°å£°éŸ³")
        return False
    #å½•éŸ³ä¿å­˜ä¸è¯­éŸ³è¯†åˆ«
    with wave.open(TRIGGER_FILE, 'wb') as wf:
        wf.setnchannels(CHANNELS)
        wf.setsampwidth(SAMPLE_WIDTH)
        wf.setframerate(SAMPLE_RATE)
        wf.writeframes(b''.join(frames))
    #å°†å½•éŸ³è½¬æ¢ä¸ºæ–‡å­—ï¼Œæ£€æŸ¥æ˜¯å¦åŒ…å«å…³é”®è¯ "å¼€å§‹å½•éŸ³"
    text = transcribe_audio(TRIGGER_FILE)
    message_queue.put(f"è§¦å‘è¯è¯†åˆ«ç»“æœï¼š{text}")
    if text and any(keyword in text for keyword in ["å¼€å§‹å½•éŸ³", "é–‹å§‹éŒ„éŸ³"]):
        #print("æ£€æµ‹åˆ°è§¦å‘è¯ 'å¼€å§‹å½•éŸ³'")
        message_queue.put("âœ… æ£€æµ‹åˆ°è§¦å‘è¯â€œå¼€å§‹å½•éŸ³â€")
        return True
    else:
        #print(f"æœªæ£€æµ‹åˆ°è§¦å‘è¯ï¼Œè¯†åˆ«ç»“æœ: {text}")
        message_queue.put("âŒ æœªæ£€æµ‹åˆ°è§¦å‘è¯ï¼Œç»§ç»­ç›‘å¬...")
        return False

def record_command():
    """æ•è·æŒ‡ä»¤éŸ³é¢‘ï¼ŒåŠ¨æ€æ—¶é•¿"""
    message_queue.put("å‡†å¤‡å½•åˆ¶æŒ‡ä»¤ï¼Œè¯·è®²è¯...")
    audio = pyaudio.PyAudio()
    stream = audio.open(format=pyaudio.paInt16,
                        channels=CHANNELS,
                        rate=SAMPLE_RATE,
                        input=True,
                        frames_per_buffer=CHUNK)

    #print("è¯·è¯´å‡ºæŒ‡ä»¤...")
    frames = []
    silence_counter = 0
    recording = False
    max_duration = 10

    while True:
        data = stream.read(CHUNK, exception_on_overflow=False)
        rms = compute_rms(data)

        if rms > RMS_THRESHOLD:
            recording = True
            frames.append(data)
            silence_counter = 0
        elif recording:
            silence_counter += CHUNK / SAMPLE_RATE
            frames.append(data)
            if silence_counter > SILENCE_DURATION:
                break

        if len(frames) * CHUNK / SAMPLE_RATE > max_duration:
            break

    stream.stop_stream()
    stream.close()
    audio.terminate()

    if not frames:
        #print("æœªå½•åˆ¶åˆ°æœ‰æ•ˆæŒ‡ä»¤")
        message_queue.put("âŒ æœªå½•åˆ¶åˆ°æœ‰æ•ˆæŒ‡ä»¤")
        return None

    with wave.open(COMMAND_FILE, 'wb') as wf:
        wf.setnchannels(CHANNELS)
        wf.setsampwidth(SAMPLE_WIDTH)
        wf.setframerate(SAMPLE_RATE)
        wf.writeframes(b''.join(frames))
    message_queue.put("æ­£åœ¨è¯†åˆ«è¯­éŸ³æŒ‡ä»¤...")
    #å°†éŸ³é¢‘æ–‡ä»¶ COMMAND_FILEï¼ˆè·¯å¾„ï¼‰è½¬ä¸ºæ–‡æœ¬
    command_text = transcribe_audio(COMMAND_FILE)
    if command_text:
        #print(f"è¯†åˆ«åˆ°çš„æŒ‡ä»¤: {command_text}")
        message_queue.put(f"âœ… è¯†åˆ«ç»“æœï¼š{command_text}")
        command = command_text.strip()
        handler = command_handlers.get(command)
        if handler:
            message_queue.put(f"æ‰§è¡ŒæŒ‡ä»¤ï¼š{command}")
            handler()
        else:
            #print(f"æœªçŸ¥æŒ‡ä»¤: {command_text}")
            message_queue.put(f"âš ï¸ æœªçŸ¥æŒ‡ä»¤ï¼š{command}")
    else:
        #print("æœªæˆåŠŸè¯†åˆ«æŒ‡ä»¤")
        message_queue.put("âŒ è¯­éŸ³è¯†åˆ«å¤±è´¥")

    return COMMAND_FILE

# def record_audio():
#     """ä¸»å‡½æ•°ï¼šç›‘å¬è§¦å‘è¯å¹¶å½•åˆ¶æŒ‡ä»¤"""
#     while True:
#         if record_trigger():
#             command_file = record_command()
#             if command_file:
#                 return command_file
#         else:
#             print("ç»§ç»­ç›‘å¬...")
#             time.sleep(1)

def record_audio_async():
    global is_listening, has_started
    try:
        message_queue.put("ğŸ™ï¸ è¯­éŸ³åŠ©æ‰‹å¼€å§‹ç›‘å¬ï¼ˆç›´åˆ°ç‚¹å‡»æŒ‰é’®æ‰‹åŠ¨å…³é—­ï¼‰...")
        while is_listening:
            if not has_started:
                # è¿˜æ²¡è§¦å‘â€œå¼€å§‹å½•éŸ³â€ï¼Œç›‘å¬è§¦å‘è¯
                if record_trigger():
                    message_queue.put("âœ… æ£€æµ‹åˆ°è§¦å‘è¯â€œå¼€å§‹å½•éŸ³â€ï¼Œè¿›å…¥æŒ‡ä»¤ç›‘å¬æ¨¡å¼")
                    has_started = True
                else:
                    time.sleep(1)
            else:
                # å·²ç»è§¦å‘ï¼ŒæŒç»­å½•åˆ¶æŒ‡ä»¤
                command_file = record_command()
                if command_file:
                    # æŒ‡ä»¤å¤„ç†æˆåŠŸæˆ–å¤±è´¥éƒ½ç»§ç»­ç›‘å¬
                    pass
                else:
                    message_queue.put("âš ï¸ æœªè¯†åˆ«åˆ°æœ‰æ•ˆæŒ‡ä»¤ï¼Œç»§ç»­ç›‘å¬...")
                time.sleep(0.1)  # è½»å¾®ä¼‘çœ é¿å…CPUé£™å‡
    except Exception as e:
        message_queue.put(f"âŒ ç›‘å¬è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯ï¼š{e}")
    finally:
        is_listening = False
        has_started = False  # é‡ç½®çŠ¶æ€
        message_queue.put("ğŸ‘‹ è¯­éŸ³åŠ©æ‰‹å·²åœæ­¢ç›‘å¬ï¼ˆç‚¹å‡»æŒ‰é’®å…³é—­ï¼‰ã€‚")

@app.route('/api/start-voice')
def start_voice():
    global is_listening
    if not is_listening:
        is_listening = True
        Thread(target=record_audio_async).start()
        return jsonify({"message": "âœ… è¯­éŸ³åŠ©æ‰‹å·²å¯åŠ¨"})
    else:
        return jsonify({"message": "âš ï¸ è¯­éŸ³åŠ©æ‰‹æ­£åœ¨è¿è¡Œä¸­"}), 400

@app.route('/api/stop-voice')
def stop_voice():
    global is_listening
    is_listening = False
    message_queue.put("ğŸ›‘ è¯­éŸ³åŠ©æ‰‹å·²æ‰‹åŠ¨åœæ­¢ç›‘å¬")
    return jsonify({"message": "ğŸ›‘ è¯­éŸ³åŠ©æ‰‹å·²æ‰‹åŠ¨åœæ­¢ç›‘å¬"})

@app.route('/api/stream')
def stream():
    def event_stream():
        try:
            while True:
                try:
                    message = message_queue.get(timeout=10)
                    yield f"data: {message}\n\n"
                except queue.Empty:
                    # å®šæœŸå‘é€å¿ƒè·³ï¼Œé¿å…æµè§ˆå™¨æ–­è¿
                    yield "data: ping\n\n"
        except GeneratorExit:
            print("å®¢æˆ·ç«¯æ–­å¼€ SSE è¿æ¥")
    return Response(stream_with_context(event_stream()), mimetype='text/event-stream')


if __name__ == "__main__":
    app.run(host='0.0.0.0', port=5000)
