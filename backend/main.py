import threading
import time
import tkinter as tk
from tkinter import ttk
from PIL import Image, ImageTk
import cv2
import datetime
import os
import dlib
import numpy as np
from imutils import face_utils

# è§†è§‰è¯†åˆ«
from sight.gaze_tracking import GazeTracking
from sight.headtrack import HeadTracker
#from sight.eyetrack import EyeTracker
# æ‰‹åŠ¿è¯†åˆ«
from gesture.gesture import SignRe
# è¯­éŸ³è¯†åˆ«
from voice import record
from user_manager import UserManager

# æ–°å¢
from log_analyzer import LogAnalyzer
from profile_analytics import ProfileAnalytics


LOG_FILE = 'log.txt'

SCENES = [
    {
        'name': 'è‡ªç”±å¤šæ¨¡æ€è¯†åˆ«',
        'desc': 'å®æ—¶å±•ç¤ºè§†è§‰ã€å¤´éƒ¨å§¿æ€ã€æ‰‹åŠ¿ã€è¯­éŸ³ç­‰å¤šæ¨¡æ€è¯†åˆ«ç»“æœï¼Œæ— åœºæ™¯è”åŠ¨ã€‚',
        'icon': '',
        'color': '#f0f4f8',
    },
    {
        'name': 'åœºæ™¯1 åˆ†å¿ƒæ£€æµ‹',
        'desc': 'åˆ†å¿ƒæ£€æµ‹ï¼šåç¦»3ç§’è§¦å‘è­¦å‘Šï¼Œéœ€æ‰‹åŠ¿/è¯­éŸ³ç¡®è®¤ã€‚\nè¾“å…¥ï¼šçœ¼åŠ¨åç¦»3ç§’ï¼Œè¯­éŸ³"å·²ç»æ³¨æ„é“è·¯"ï¼Œæ‰‹åŠ¿ç«–æ‹‡æŒ‡/æŒ¥æ‰‹ã€‚\nè¾“å‡ºï¼šçº¢è‰²è­¦å‘Šæ ï¼Œè¯­éŸ³æ’­æŠ¥ï¼Œè­¦å‘Šç¯é—ªçƒã€‚',
        'icon': 'ğŸš¨',
        'color': '#ff3333',
        'audio1': r'E:\system\voice\temp\security_converted.wav',  # "å·²æ³¨æ„è¡Œè½¦å®‰å…¨"
        'audio2': r'E:\system\voice\temp\look_straight.wav',      # "è¯·ç«‹å³ç›®è§†å‰æ–¹"
    },
    {
        'name': 'åœºæ™¯2 å¯¼èˆªç¡®è®¤',
        'desc': 'å¯¼èˆªç¡®è®¤ï¼šå‘ä¸‹çœ‹åç‚¹å¤´ä¸ºç¡®è®¤ï¼Œæ‘‡å¤´ä¸ºé‡é€‰ã€‚\nè¾“å…¥ï¼šçœ¼åŠ¨å‘ä¸‹ï¼Œç‚¹å¤´/æ‘‡å¤´ã€‚\nè¾“å‡ºï¼šè“/é»„çŠ¶æ€æ ï¼Œè¯­éŸ³æ’­æŠ¥ï¼Œå¯¼èˆªå›¾æ ‡é—ªçƒã€‚',
        'icon': 'ğŸ§­',
        'color': '#3399ff',
        'color2': '#ffd700',
        'audio1': r'E:\system\voice\temp\navigation_converted.wav',  # "å·²å¼€å¯å¯¼èˆª"
        'audio2': r'E:\system\voice\temp\navigation_converted.wav',
    },
    {
        'name': 'åœºæ™¯3 éŸ³ä¹çŠ¶æ€',
        'desc': 'éŸ³ä¹çŠ¶æ€ï¼šå‘å·¦çœ‹ç«–æ‹‡æŒ‡ä¸ºæ’­æ”¾ï¼ŒæŒ¥æ‰‹ä¸ºæš‚åœã€‚\nè¾“å…¥ï¼šçœ¼åŠ¨å‘å·¦ï¼Œæ‰‹åŠ¿ç«–æ‹‡æŒ‡/æŒ¥æ‰‹ã€‚\nè¾“å‡ºï¼šç»¿/é»„çŠ¶æ€æ ï¼Œè¯­éŸ³æ’­æŠ¥ï¼ŒéŸ³ä¹å›¾æ ‡é—ªçƒã€‚',
        'icon': 'ğŸµ',
        'color': '#33cc66',
        'color2': '#ffd700',
        'audio1': r'E:\system\voice\temp\music1_converted.wav',  # éŸ³ä¹æ’­æ”¾
        'audio2': r'',
    },
]

# å¤´éƒ¨å§¿æ€æ£€æµ‹ç±»ï¼ˆé›†æˆè‡ªsight/headtrack.pyæ ¸å¿ƒé€»è¾‘ï¼Œè¾“å‡ºç‚¹å¤´/æ‘‡å¤´/é™æ­¢ï¼‰
class HeadPoseDetector:
    def __init__(self, predictor_path='sight/gaze_tracking/trained_models/shape_predictor_68_face_landmarks.dat'):
        self.face_detector = dlib.get_frontal_face_detector()
        self.landmark_predictor = dlib.shape_predictor(predictor_path)
        self.nod_counter = 0
        self.shake_counter = 0
        self.last_status = 'é™æ­¢'
        self.nod_flag = False
        self.shake_flag = False
        self.nod_time = 0
        self.shake_time = 0

    def get_pose(self, frame):
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        faces = self.face_detector(gray, 0)
        status = 'é™æ­¢'
        for face in faces:
            shape = self.landmark_predictor(gray, face)
            shape = face_utils.shape_to_np(shape)
            # ç‚¹å¤´æ£€æµ‹ï¼ˆçœ‰æ¯›åˆ°ä¸‹é¢Œè·ç¦»å˜åŒ–ï¼‰
            brow = shape[21:27]  # å·¦å³çœ‰æ¯›
            jaw = shape[6:11]    # ä¸‹é¢Œ
            brow_y = np.mean(brow[:, 1])
            jaw_y = np.mean(jaw[:, 1])
            dist = jaw_y - brow_y
            # é˜ˆå€¼å¯æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´
            if dist > 70 and not self.nod_flag:
                self.nod_counter += 1
                self.nod_flag = True
                self.nod_time = time.time()
                status = 'ç‚¹å¤´'
            elif dist <= 70:
                self.nod_flag = False
            # æ‘‡å¤´æ£€æµ‹ï¼ˆå·¦å³ä¸‹é¢Œè·ç¦»å˜åŒ–ï¼‰
            jaw_left = shape[6]
            jaw_right = shape[10]
            nose = shape[30]
            if (jaw_left[0] - nose[0] > 40 or nose[0] - jaw_right[0] > 40) and not self.shake_flag:
                self.shake_counter += 1
                self.shake_flag = True
                self.shake_time = time.time()
                status = 'æ‘‡å¤´'
            elif abs(jaw_left[0] - nose[0]) <= 40 and abs(nose[0] - jaw_right[0]) <= 40:
                self.shake_flag = False
            # çŠ¶æ€ä¿æŒ1ç§’
            if self.nod_flag and time.time() - self.nod_time < 1:
                status = 'ç‚¹å¤´'
            elif self.shake_flag and time.time() - self.shake_time < 1:
                status = 'æ‘‡å¤´'
        if status == 'é™æ­¢' and (self.nod_flag or self.shake_flag):
            # ä¿æŒä¸Šä¸€æ¬¡çŠ¶æ€ç›´åˆ°åŠ¨ä½œç»“æŸ
            status = self.last_status
        self.last_status = status
        return status

USER_TYPES = ['é©¾é©¶å‘˜', 'ä¹˜å®¢', 'ç»´æŠ¤äººå‘˜', 'ç®¡ç†äººå‘˜']
USER_PERMISSIONS = {
    'é©¾é©¶å‘˜': 'å¯æ“ä½œé©¾é©¶ç›¸å…³åŠŸèƒ½ï¼ŒæŸ¥çœ‹å¤šæ¨¡æ€è¯†åˆ«ç»“æœ',
    'ä¹˜å®¢': 'ä»…å¯æŸ¥çœ‹å¤šæ¨¡æ€è¯†åˆ«ç»“æœï¼Œéƒ¨åˆ†æ“ä½œå—é™',
    'ç»´æŠ¤äººå‘˜': 'å¯æŸ¥çœ‹ç³»ç»Ÿæ—¥å¿—ï¼Œç»´æŠ¤ç³»ç»Ÿ',
    'ç®¡ç†äººå‘˜': 'å¯ç®¡ç†æ‰€æœ‰ç”¨æˆ·å’Œç³»ç»Ÿè®¾ç½®ï¼Œæ‹¥æœ‰å…¨éƒ¨æƒé™'
}

class User:
    def __init__(self, username, user_type):
        self.username = username
        self.user_type = user_type
        self.permissions = USER_PERMISSIONS.get(user_type, '')

class MultiModalApp:
    def __init__(self, root):
        self.root = root
        self.root.title('è½¦è½½å¤šæ¨¡æ€äº¤äº’ç³»ç»Ÿ')
        self.root.geometry('1200x700')
        self.root.resizable(False, False)
        self.root.configure(bg='#f0f4f8')

        self.scene_idx = 0
        self.scene_state = {}
        self.flash_flag = True
        self.last_gaze_time = time.time()
        self.gaze_off_road = False
        self.warning_active = False
        self.last_warning_time = 0
        self.music_playing = True
        self.music_checked = False
        self.navigation_checked = False
        self.navigation_reselect = False
        self.last_status = ''
        self.gesture_pause_buffer = []  # ç”¨äºéŸ³ä¹åœºæ™¯æŒ¥æ‰‹å»æŠ–åŠ¨

        # å·¦ä¾§åœºæ™¯åˆ‡æ¢æ 
        self.scene_frame = tk.Frame(self.root, bg='#e3eaf2')
        self.scene_frame.place(x=0, y=0, width=260, height=700)
        self.scene_buttons = []
        for i, scene in enumerate(SCENES):
            btn = tk.Button(self.scene_frame, text=scene['name'], font=('å¾®è½¯é›…é»‘', 13, 'bold'),
                            bg='#e3eaf2', fg='#1a73e8', bd=0, relief='flat',
                            activebackground='#c6dafc', activeforeground='#d32f2f',
                            command=lambda idx=i: self.switch_scene(idx))
            btn.place(x=20, y=30 + i*60, width=220, height=50)
            self.scene_buttons.append(btn)
        self.update_scene_buttons()

        # å¤šæ¨¡æ€è¾“å‡ºåŒºï¼ˆå·¦ä¸‹ï¼‰
        self.result_frame = tk.Frame(self.scene_frame, bg='#f7fafc', highlightbackground='#1a73e8', highlightthickness=2)
        self.result_frame.place(x=10, y=320, width=240, height=350)
        self.result_title = tk.Label(self.result_frame, text='å¤šæ¨¡æ€è¯†åˆ«ç»“æœ', font=('å¾®è½¯é›…é»‘', 14, 'bold'), fg='#1a73e8', bg='#f7fafc')
        self.result_title.pack(pady=(10, 0))
        self.result_text = tk.Text(self.result_frame, font=('å¾®è½¯é›…é»‘', 12), wrap='word', bg='#f7fafc', fg='#222',
                                   relief='flat', borderwidth=0, height=16)
        self.result_text.pack(fill='both', expand=True, padx=8, pady=8)
        self.result_text.tag_configure('label', foreground='#1a73e8', font=('å¾®è½¯é›…é»‘', 12, 'bold'))
        self.result_text.tag_configure('value', foreground='#222', font=('å¾®è½¯é›…é»‘', 12))

        # å³ä¾§åœºæ™¯æè¿°åŒº
        self.welcome_label = tk.Label(self.root, text='æ¬¢è¿è¿›å…¥è½¦è½½å¤šæ¨¡æ€äº¤äº’ç³»ç»Ÿ',
                                      font=('å¾®è½¯é›…é»‘', 18, 'bold'), fg='#1a73e8', bg='#f0f4f8', anchor='w')
        self.welcome_label.place(x=270, y=10, width=1100, height=32)
        self.scene_desc = tk.Label(self.root, text=SCENES[self.scene_idx]['desc'],
                                   font=('å¾®è½¯é›…é»‘', 11), fg='#333', bg='#f0f4f8', justify='left', anchor='nw')
        self.scene_desc.place(x=270, y=45, width=1100, height=140)
        self.sep1 = tk.Frame(self.root, bg='#1a73e8')
        self.sep1.place(x=270, y=190, width=1100, height=2)

        # å³ä¾§æ‘„åƒå¤´ç”»é¢
        self.video_label = tk.Label(self.root, bg='#222')
        self.video_label.place(x=270, y=190, width=900, height=480)

        # çŠ¶æ€æ å’Œä»ªè¡¨ç›˜å›¾æ ‡ï¼ˆå³ä¸Šè§’ï¼Œæ‘„åƒå¤´ç”»é¢ä¸Šæ–¹ï¼‰
        self.status_label = tk.Label(self.root, text='', font=('å¾®è½¯é›…é»‘', 18, 'bold'), bg='#f0f4f8')
        self.status_label.place(x=270, y=150, width=700, height=40)
        self.icon_label = tk.Label(self.root, text='', font=('å¾®è½¯é›…é»‘', 40), bg='#f0f4f8')
        self.icon_label.place(x=980, y=150, width=80, height=40)

        # ç”¨æˆ·ç®¡ç†
        self.user_manager = UserManager()
        self.create_user_panel()

        # åˆå§‹åŒ–è¯†åˆ«å™¨
        self.gaze = GazeTracking()
        self.gesture = SignRe()
        self.headpose = HeadTracker()
        self.cap = cv2.VideoCapture(0)
        #self.eyetracker = EyeTracker()

        self.last_gaze = ''
        self.last_gesture = ''
        self.last_voice = ''
        self.last_gaze_type = ''
        self.last_gesture_type = ''
        self.last_voice_type = ''
        self.last_headpose = 'é™æ­¢'

        self.update_frame()
        # self.voice_thread = threading.Thread(target=self.voice_recognition_loop, daemon=True)
        # self.voice_thread.start()
        self.flash_timer()

        # æ–°å¢
        self.log_analyzer = LogAnalyzer()
        self.profile_analytics = ProfileAnalytics()

    # æ–°å¢
    def on_interaction_complete(self, mode, content):
        # åœ¨äº¤äº’å®Œæˆåè°ƒç”¨åˆ†æ
        if hasattr(self, 'user_manager') and self.user_manager:
            username = self.user_manager.get_current_user().username
            self.log_analyzer.analyze_user_behavior(username)

    def switch_scene(self, idx):
        self.scene_idx = idx
        self.scene_desc.config(text=SCENES[self.scene_idx]['desc'])
        self.update_scene_buttons()
        # é‡ç½®åœºæ™¯çŠ¶æ€
        self.gaze_off_road = False
        self.warning_active = False
        self.last_gaze_time = time.time()
        self.music_checked = False
        self.navigation_checked = False
        self.navigation_reselect = False
        self.status_label.config(text='', bg='#f0f4f8')
        self.icon_label.config(text='', bg='#f0f4f8')

    def update_scene_buttons(self):
        for i, btn in enumerate(self.scene_buttons):
            if i == self.scene_idx:
                btn.config(bg='#1a73e8', fg='white')
            else:
                btn.config(bg='#e3eaf2', fg='#1a73e8')

    def update_frame(self):
        ret, frame = self.cap.read()
        if not ret:
            self.root.after(30, self.update_frame)
            return


        # å¤´éƒ¨å§¿æ€
        headpose_result = self.headpose.get_status(frame)
        self.last_headpose = headpose_result

        # æ‰‹åŠ¿è¯†åˆ«
        gesture_result = self.detect_gesture(frame)

        # ç›®å…‰åŒºåŸŸ
        # gaze_result = self.eyetracker.get_status(frame)
        # self.last_gaze = gaze_result# self.gaze.refresh(frame)
        self.gaze.refresh(frame)
        #frame = self.gaze.annotated_frame()
        gaze_result = ''
        if self.gaze.look_down():
            gaze_result = 'å‘ä¸‹çœ‹'
        elif self.gaze.look_right():
            gaze_result = 'å‘å³çœ‹'
        elif self.gaze.look_left():
            gaze_result = 'å‘å·¦çœ‹'
        elif self.gaze.look_center():
            gaze_result = 'çœ¼ç›å±…ä¸­'
        else:
            gaze_result = 'æœªæ£€æµ‹åˆ°çœ¼åŠ¨'
        self.last_gaze = gaze_result

        # ç”»é¢æ˜¾ç¤º
        #display_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        show_frame = self.gaze.annotated_frame()
        if show_frame is None:
            show_frame = frame

        display_frame = cv2.cvtColor(show_frame, cv2.COLOR_BGR2RGB)
        img = Image.fromarray(display_frame)
        img = img.resize((900, 480))
        imgtk = ImageTk.PhotoImage(image=img)
        self.video_label.imgtk = imgtk
        self.video_label.configure(image=imgtk)

        # åœºæ™¯é€»è¾‘
        self.handle_scene_logic(gaze_result, headpose_result, gesture_result)

        # ç»“æœæ–‡æœ¬ç¾åŒ–è¾“å‡º
        self.result_text.config(state='normal')
        self.result_text.delete(1.0, tk.END)
        self.result_text.insert(tk.END, 'è§†è§‰: ', 'label')
        self.result_text.insert(tk.END, f'{gaze_result}\n', 'value')
        self.result_text.insert(tk.END, 'å¤´éƒ¨å§¿æ€: ', 'label')
        self.result_text.insert(tk.END, f'{headpose_result}\n', 'value')
        self.result_text.insert(tk.END, 'æ‰‹åŠ¿: ', 'label')
        self.result_text.insert(tk.END, f'{gesture_result}\n', 'value')
        self.result_text.insert(tk.END, 'è¯­éŸ³: ', 'label')
        self.result_text.insert(tk.END, f'{self.last_voice}\n', 'value')
        self.result_text.config(state='disabled')

        self.root.after(30, self.update_frame)

    def detect_gesture(self, frame):
        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        with self.gesture.mp_hands.Hands(
            static_image_mode=False,
            max_num_hands=2,
            model_complexity=0,
            min_detection_confidence=0.5,
            min_tracking_confidence=0.5
        ) as hands:
            results = hands.process(rgb_frame)
            if results.multi_hand_landmarks:
                for hand_landmarks in results.multi_hand_landmarks:
                    self.gesture.ges(hand_landmarks)
                gesture = self.gesture.get_last_gesture()
                return gesture if gesture else 'æ— æ‰‹åŠ¿'
        return 'æ— æ‰‹åŠ¿'

    def handle_scene_logic(self, gaze_result, headpose_result, gesture_result):
        scene = SCENES[self.scene_idx]
        # è‡ªç”±å¤šæ¨¡æ€è¯†åˆ«æ¨¡å¼ï¼šåªå±•ç¤ºï¼Œä¸è”åŠ¨
        if self.scene_idx == 0:
            self.status_label.config(text='', bg='#f0f4f8')
            self.icon_label.config(text='', bg='#f0f4f8')
            return
        # åœºæ™¯1 åˆ†å¿ƒæ£€æµ‹
        if self.scene_idx == 1:
            if gaze_result in ['å‘å·¦çœ‹', 'å‘å³çœ‹', 'å‘ä¸‹çœ‹']:
                if not self.gaze_off_road:
                    self.gaze_off_road = True
                    self.last_gaze_time = time.time()
                elif time.time() - self.last_gaze_time > 3 and not self.warning_active:
                    self.warning_active = True
                    self.status_label.config(text='è­¦å‘Šï¼è¯·ç›®è§†å‰æ–¹', bg=scene['color'], fg='white')
                    self.icon_label.config(text=scene['icon'], bg=scene['color'])
                    record.play_audio(scene['audio1'])
                    self.log_result('è­¦å‘Š', 'è¯·ç›®è§†å‰æ–¹')
            else:
                self.gaze_off_road = False
                self.last_gaze_time = time.time()
                # åªæœ‰è§£é™¤è­¦å‘Šæ—¶æ‰é‡ç½®çŠ¶æ€æ 
                # if self.warning_active:
                #     self.status_label.config(text='', bg='#f0f4f8')
                #     self.icon_label.config(text='', bg='#f0f4f8')
                #     self.warning_active = False
            # è§£é™¤è­¦å‘Šé€»è¾‘ï¼Œè­¦å‘ŠæœŸé—´æ¯å¸§éƒ½æ£€æµ‹
            if self.warning_active:
                if self.last_voice == 'å·²ç»æ³¨æ„é“è·¯' or gesture_result == 'ç«–æ‹‡æŒ‡':
                    self.status_label.config(text='å®‰å…¨å·²ç¡®è®¤', bg='#33cc66', fg='white')
                    self.icon_label.config(text=scene['icon'], bg='#33cc66')
                    self.warning_active = False
                    self.log_result('ç¡®è®¤', 'å®‰å…¨å·²ç¡®è®¤')
                elif gesture_result == 'æŒ¥æ‰‹':
                    self.status_label.config(text='è­¦å‘Šæœªè§£é™¤', bg=scene['color'], fg='white')
                    self.icon_label.config(text=scene['icon'], bg=scene['color'])
                    self.log_result('æ‹’ç»', 'è­¦å‘Šæœªè§£é™¤')
        # åœºæ™¯2 å¯¼èˆªç¡®è®¤
        elif self.scene_idx == 2:
            if gaze_result == 'å‘ä¸‹çœ‹' and not self.navigation_checked:
                self.status_label.config(text='è¯·ç‚¹å¤´ç¡®è®¤å¯¼èˆªè·¯çº¿', bg=scene['color'], fg='white')
                self.icon_label.config(text=scene['icon'], bg=scene['color'])
                self.navigation_checked = True
            if self.navigation_checked:
                if headpose_result == 'ç‚¹å¤´':
                    self.status_label.config(text='å¯¼èˆªè·¯çº¿å·²ç¡®è®¤', bg=scene['color'], fg='white')
                    self.icon_label.config(text=scene['icon'], bg=scene['color'])
                    record.play_audio(scene['audio1'])
                    self.log_result('å¯¼èˆª', 'å¯¼èˆªè·¯çº¿å·²ç¡®è®¤')
                elif headpose_result == 'æ‘‡å¤´':
                    self.status_label.config(text='è¯·é‡æ–°é€‰æ‹©å¯¼èˆªè·¯çº¿', bg=scene['color2'], fg='black')
                    self.icon_label.config(text=scene['icon'], bg=scene['color2'])
                    record.play_audio(scene['audio2'])
                    self.log_result('å¯¼èˆª', 'è¯·é‡æ–°é€‰æ‹©å¯¼èˆªè·¯çº¿')
        # åœºæ™¯3 éŸ³ä¹çŠ¶æ€
        elif self.scene_idx == 3:
            if gaze_result == 'å‘å·¦çœ‹' and not self.music_checked:
                self.status_label.config(text='è¯·ç«–æ‹‡æŒ‡ç¡®è®¤éŸ³ä¹çŠ¶æ€', bg=scene['color'], fg='white')
                self.icon_label.config(text=scene['icon'], bg=scene['color'])
                self.music_checked = True
            if self.music_checked:
                if gesture_result == 'ç«–æ‹‡æŒ‡':
                    self.status_label.config(text='éŸ³ä¹æ­£åœ¨æ’­æ”¾', bg=scene['color'], fg='white')
                    self.icon_label.config(text=scene['icon'], bg=scene['color'])
                    record.play_audio(scene['audio1'])
                    self.log_result('éŸ³ä¹', 'éŸ³ä¹æ­£åœ¨æ’­æ”¾')
                    self.gesture_pause_buffer.clear()
                elif gesture_result == 'æŒ¥æ‰‹':
                    self.gesture_pause_buffer.append('æŒ¥æ‰‹')
                    if len(self.gesture_pause_buffer) >= 2 and all(g == 'æŒ¥æ‰‹' for g in self.gesture_pause_buffer[-2:]):
                        self.status_label.config(text='éŸ³ä¹å·²æš‚åœ', bg=scene['color2'], fg='black')
                        self.icon_label.config(text=scene['icon'], bg=scene['color2'])
                        record.stop_audio()  # ç«‹å³åœæ­¢éŸ³ä¹
                        self.log_result('éŸ³ä¹', 'éŸ³ä¹å·²æš‚åœ')
                        self.gesture_pause_buffer.clear()
                else:
                    self.gesture_pause_buffer.clear()

        # æ–°å¢
        # æ›´æ–°ç”¨æˆ·é…ç½®
        if hasattr(self, 'user_manager') and self.user_manager:
            username = self.user_manager.get_current_user().username
            self.profile_analytics.update_profile_based_on_interaction(
                username,
                SCENES[self.scene_idx]['name'],
                f"{gaze_result}|{gesture_result}"
            )


    def flash_timer(self):
        # ä»ªè¡¨ç›˜å’ŒçŠ¶æ€æ é—ªçƒ
        scene = SCENES[self.scene_idx]
        if self.status_label.cget('text') and self.status_label.cget('bg') != '#f0f4f8':
            if self.flash_flag:
                self.status_label.config(bg=scene.get('color', '#ff3333'))
                self.icon_label.config(bg=scene.get('color', '#ff3333'))
            else:
                self.status_label.config(bg='#f0f4f8')
                self.icon_label.config(bg='#f0f4f8')
            self.flash_flag = not self.flash_flag
        self.root.after(500, self.flash_timer)

    # def voice_recognition_loop(self):
    #     print("[DEBUG] è¯­éŸ³è¯†åˆ«çº¿ç¨‹å¯åŠ¨")
    #     while True:
    #         try:
    #             print("[DEBUG] è°ƒç”¨record_audio()")
    #             result = record.record_audio()
    #             print(f"[DEBUG] record_audioè¿”å›: {result}")
    #             if result:
    #                 self.last_voice = result
    #             else:
    #                 self.last_voice = ''
    #         except Exception as e:
    #             self.last_voice = f'è¯­éŸ³è¯†åˆ«å¼‚å¸¸: {e}'
    #             import traceback
    #             traceback.print_exc()
    #         time.sleep(1)
    # def voice_recognition_loop(self):
    #     print("[DEBUG] è¯­éŸ³è¯†åˆ«çº¿ç¨‹å¯åŠ¨")

    #     def update_voice_message(msg):
    #         self.last_voice = msg
    #         self.result_text.config(state='normal')

    #         # å…ˆæ¸…é™¤ä¹‹å‰çš„â€œè¯­éŸ³â€è¡Œï¼ˆæ‰¾åˆ°åŒ…å«â€œè¯­éŸ³:â€æ ‡ç­¾çš„è¡Œï¼‰
    #         start = self.result_text.search("è¯­éŸ³:", "1.0", stopindex="end")
    #         if start:
    #             line = start.split('.')[0]
    #             self.result_text.delete(f"{line}.0", f"{int(line)+1}.0")

    #         # æ’å…¥æ–°çš„â€œè¯­éŸ³â€ä¿¡æ¯
    #         self.result_text.insert(tk.END, 'è¯­éŸ³: ', 'label')
    #         self.result_text.insert(tk.END, f'{msg}\n', 'value')

    #     k    self.result_text.config(state='disabled')

    #     record.record_audio_loop(update_voice_message)
    def voice_recognition_loop(self):
        print("[DEBUG] è¯­éŸ³è¯†åˆ«çº¿ç¨‹å¯åŠ¨")

        def update_voice_message(msg):
            def _update():
                self.last_voice = msg
                self.result_text.config(state='normal')

                # æ¸…é™¤æ—§çš„â€œè¯­éŸ³â€è¡Œ
                start = self.result_text.search("è¯­éŸ³:", "1.0", stopindex="end")
                if start:
                    line = start.split('.')[0]
                    self.result_text.delete(f"{line}.0", f"{int(line)+1}.0")

                # æ’å…¥æ–°çš„â€œè¯­éŸ³â€ä¿¡æ¯
                self.result_text.insert(tk.END, 'è¯­éŸ³: ', 'label')
                self.result_text.insert(tk.END, f'{msg}\n', 'value')

                self.result_text.config(state='disabled')

            # ä¿è¯ UI æ›´æ–°åœ¨ä¸»çº¿ç¨‹ä¸­æ‰§è¡Œ
            self.result_text.after(0, _update)

        # å¯åŠ¨è¯­éŸ³è¯†åˆ«ç›‘å¬
        record.record_audio_loop(update_voice_message)



    def log_result(self, mode, content):
        if not content or content == 'æ— æ‰‹åŠ¿' or content == 'æœªæ£€æµ‹åˆ°çœ¼åŠ¨':
            return
        now = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        user = self.user_manager.get_current_user().username if hasattr(self, 'user_manager') and self.user_manager else 'unknown'
        log_line = f'[{now}] [{user}] {mode}: {content}\n'
        with open(LOG_FILE, 'a', encoding='utf-8') as f:
            f.write(log_line)

    def create_user_panel(self):
        self.user_var = tk.StringVar(value=self.user_manager.get_current_user().username)
        user_names = self.user_manager.get_usernames()
        self.user_menu = ttk.Combobox(self.root, textvariable=self.user_var, values=user_names, state='readonly')
        self.user_menu.place(x=1050, y=10, width=120, height=30)
        self.user_menu.bind('<<ComboboxSelected>>', self.on_user_change)
        # æƒé™æ˜¾ç¤ºæ ‡ç­¾
        user = self.user_manager.get_current_user()
        self.permission_label = tk.Label(
            self.root,
            text=f"å½“å‰ç”¨æˆ·: {user.username} ({user.user_type})\næƒé™: {user.permissions}",
            font=('å¾®è½¯é›…é»‘', 10), fg='#666', bg='#f0f4f8', anchor='w', justify='left'
        )
        self.permission_label.place(x=900, y=45, width=270, height=50)

    def on_user_change(self, event=None):
        username = self.user_var.get()
        self.user_manager.set_current_user(username)
        self.update_user_permission()

    def update_user_permission(self):
        user = self.user_manager.get_current_user()
        self.permission_label.config(
            text=f"å½“å‰ç”¨æˆ·: {user.username} ({user.user_type})\næƒé™: {user.permissions}"
        )

if __name__ == '__main__':
    root = tk.Tk()
    app = MultiModalApp(root)

    # æ–°å¢ ç­‰å¾…ä¸»ç•Œé¢å®Œæˆåˆå§‹åŒ–åå†å¯åŠ¨çº¿ç¨‹
    def start_voice_thread():
        app.voice_thread = threading.Thread(target=app.voice_recognition_loop, daemon=True)
        app.voice_thread.start()
    root.after(1000, start_voice_thread)  # å»¶è¿Ÿ1ç§’å†å¯åŠ¨çº¿ç¨‹

    root.mainloop()